{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAYN.classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEC_LN_-Hfe9",
        "colab_type": "code",
        "outputId": "aa555fc7-524a-49ea-9786-d5e5ad118849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install TurkishStemmer gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: TurkishStemmer in /usr/local/lib/python3.6/dist-packages (1.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.224)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.224 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.224)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lycJJPJGg6T",
        "colab_type": "code",
        "outputId": "36c92572-13d5-4ffb-b407-6663bd8bab2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from TurkishStemmer import TurkishStemmer\n",
        "from gensim.models import Word2Vec\n",
        "import multiprocessing\n",
        "import pandas as pd\n",
        "import string\n",
        "pd.options.display.max_colwidth = 8000\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwD6t3T-HTex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/naynco/nayn.data/master/classification_clean.csv\")\n",
        "df.dropna().reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXDmsKr3reHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = np.array(df['Title'])\n",
        "classes = np.array(df['Categories'])\n",
        "df_docs = pd.DataFrame({'Document': docs, \n",
        "                        'Class': classes})\n",
        "df_docs = df_docs[['Document', 'Class']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgfUM5Hl6mij",
        "colab_type": "code",
        "outputId": "d9304a38-e1b6-41e9-b601-78d0dfa63d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "df['Categories'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SICAK                    16889\n",
              "GÜNDEM                   12983\n",
              "DÜNYA                     9226\n",
              "SPOR                      1967\n",
              "GÜNDEM|SICAK              1135\n",
              "DÜNYA|SICAK                458\n",
              "SANAT                      285\n",
              "DÜNYA|GÜNDEM               207\n",
              "Teknoloji                  144\n",
              "Video                      100\n",
              "DÜNYA|SPOR                  76\n",
              "DÜNYA|Teknoloji             73\n",
              "SICAK|SPOR                  51\n",
              "GÜNDEM|SPOR                 33\n",
              "DÜNYA|SANAT                 27\n",
              "SANAT|Video                 21\n",
              "DÜNYA|Video                 20\n",
              "GÜNDEM|SANAT                19\n",
              "SPOR|Video                  17\n",
              "GÜNDEM|Teknoloji            10\n",
              "DÜNYA|GÜNDEM|SPOR            8\n",
              "GÜNDEM|Video                 5\n",
              "News                         3\n",
              "DÜNYA|GÜNDEM|SICAK           3\n",
              "SICAK|Teknoloji              1\n",
              "SPOR|Teknoloji               1\n",
              "DÜNYA|GÜNDEM|SANAT           1\n",
              "DÜNYA|Teknoloji|Video        1\n",
              "SICAK|Video                  1\n",
              "SANAT|SICAK                  1\n",
              "Name: Categories, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1B6XKfwOMEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WPT = nltk.WordPunctTokenizer()\n",
        "stop_word_list = nltk.corpus.stopwords.words('turkish')\n",
        "\n",
        "def norm_doc(single_doc):\n",
        "    # TR: Dokümandan belirlenen özel karakterleri ve sayıları at\n",
        "    # EN: Remove special characters and numbers\n",
        "    single_doc = re.sub(\" \\d+\", \" \", single_doc)\n",
        "    pattern = r\"[{}]\".format(\",.;\") \n",
        "    single_doc = re.sub(pattern, \"\", single_doc) \n",
        "    # TR: Dokümanı küçük harflere çevir\n",
        "    # EN: Convert document to lowercase\n",
        "    single_doc = single_doc.lower()\n",
        "    single_doc = single_doc.strip()\n",
        "    # TR: Dokümanı token'larına ayır\n",
        "    # EN: Tokenize documents\n",
        "    tokens = WPT.tokenize(single_doc)\n",
        "    # TR: Stop-word listesindeki kelimeler hariç al\n",
        "    # EN: Filter out the stop-words \n",
        "    filtered_tokens = [token for token in tokens if token not in stop_word_list]\n",
        "    # TR: Dokümanı tekrar oluştur\n",
        "    # EN: Reconstruct the document\n",
        "    single_doc = ' '.join(filtered_tokens)\n",
        "    return single_doc\n",
        "\n",
        "norm_docs = np.vectorize(norm_doc) #like magic :)\n",
        "normalized_documents = norm_docs(docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG-kcZLVu9qA",
        "colab_type": "code",
        "outputId": "986335ff-7969-41d0-d317-4b099f611890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "BoW_Vector = CountVectorizer(min_df = 0., max_df = 1.)\n",
        "BoW_Matrix = BoW_Vector.fit_transform(normalized_documents)\n",
        "#print (BoW_Matrix)\n",
        "\n",
        "# TR: BoW_Vector içerisindeki tüm öznitelikleri al\n",
        "# EN: Fetch al features in BoW_Vector\n",
        "features = BoW_Vector.get_feature_names()\n",
        "print (\"features[50]:\" + features[46])\n",
        "print (\"features[52]:\" +features[48])\n",
        "\n",
        "BoW_Matrix = BoW_Matrix.toarray()\n",
        "# TR: Doküman - öznitelik matrisini göster\n",
        "# EN: Print document by term matrice\n",
        "BoW_df = pd.DataFrame(BoW_Matrix, columns = features)\n",
        "#print(BoW_df.info())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features[50]:140\n",
            "features[52]:145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgPBQCTNv7UD",
        "colab_type": "code",
        "outputId": "98a42ed7-6380-4f58-8f19-3fa779125d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "number_of_topics = 20\n",
        "BoW_Matrix = BoW_Vector.fit_transform(normalized_documents)\n",
        "LDA = LatentDirichletAllocation(n_components = number_of_topics, \n",
        "                                max_iter = 10, \n",
        "                                learning_offset = 50.,\n",
        "                                random_state = 0,\n",
        "                                learning_method = 'online').fit(BoW_Matrix)\n",
        "features = BoW_Vector.get_feature_names()\n",
        "for t_id, topic in enumerate(LDA.components_):\n",
        "    print (\"Topic %d:\" % (t_id))\n",
        "    print (\" \".join([features[i]\n",
        "                    for i in topic.argsort()[:-number_of_topics - 1:-1]]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "açıklaması srail un rus dan kaybetti hayatını afrin bakan yunanistan göre aday albayrak krizi ordusu emre savaşı of ekonomik önünde\n",
            "Topic 1:\n",
            "suudi kaşıkçı ta arabistan kadar ankara olarak operasyonu lk hava serbest temmuz dakika gül prens ün açıldı edildi cia nı\n",
            "Topic 2:\n",
            "stanbul başkanı rusya eski verdi nun savaş destek tehdit terör nato cinsel nedeniyle dlib belediye vurdu bankası merkel akar verildi\n",
            "Topic 3:\n",
            "den geldi fazla ali ilgili açıklama lira görüştü zmir gazze uyarı yüksek hindistan yüzünden üzerine birlikte tazminat adı olsun ölüm\n",
            "Topic 4:\n",
            "var son kılıçdaroğlu tl bulundu la olacak in twitter davasında su davası yılın deniz hakaret anlattı yanlış buldu ceo üniversitesi\n",
            "Topic 5:\n",
            "nin türkiye kişi geliyor tepki eden ahmet yı facebook tutuklandı koç suriyeli sert bedelli iddia açtı maduro gazeteci kar askerlik\n",
            "Topic 6:\n",
            "bin açıkladı yaptı geçti olabilir soylu yılmaz önce adayı nden adalet yapan brunson hollanda güneş iş ortak çişleri bana araç\n",
            "Topic 7:\n",
            "erdoğan dan cumhurbaşkanı dünya te hapis akşener cezası fatih mhp el gün para arda ay ediyor turan irak ben terim\n",
            "Topic 8:\n",
            "na fransa ten almanya edildi pkk özel devlet mi kabul etti bahçeli dedi tahliye yorumu tarihi japonya gökçek haber yardım\n",
            "Topic 9:\n",
            "ye türkiye büyük yaşındaki kuzey gözaltı sayısı beyaz dünyanın öldürüldü aziz terörist işi ait girdi fetö yıldırım çin spanya menbiç\n",
            "Topic 10:\n",
            "trump yi parti ak in yüzde türk türkiye hakkında ab avrupa partili atatürk gülen macron oy saray zam havalimanı suç\n",
            "Topic 11:\n",
            "nın yıl sonra tsk yeniden soruşturma çağrısı arttı kimyasal meksika yakın musk adana üyesi duyurdu elon haziran başlatıldı tesla iade\n",
            "Topic 12:\n",
            "daki ölü ngiltere geri yaralı öldü başbakanı netanyahu ağır olur üç birliği suçlanan venezüella askerleri may raporu afganistan ntihar skripal\n",
            "Topic 13:\n",
            "milyar dolarlık new york times karamollaoğlu veliaht selman yaşamını yitirdi yangın satıldı cnn portakal olmayan çipras kıbrıs arıyor 2018 fiyatı\n",
            "Topic 14:\n",
            "abd oldu çin milyon etti ın putin galatasaray saldırı değil nce karşı belli polis in milli euro yanıt diyen operasyon\n",
            "Topic 15:\n",
            "bir yeni kararı dolar kadın sosyal aldı apple medya beni dava yılda dışı iphone ele washington saat rekor adam ettiği\n",
            "Topic 16:\n",
            "tan alındı gözaltına hdp çocuk beşiktaş iki in istiyor kaldı yerine kudüs talya özür müdürü adım brexit emniyet attı görevden\n",
            "Topic 17:\n",
            "dan ilk fetö başladı yıldırım şehit asker uyarısı bakanlığı sonrası askeri başbakan darbe çavuşoğlu düştü karar konusunda ardından mesajı nün\n",
            "Topic 18:\n",
            "chp li ndan ran fenerbahçe seçim kore başkan devam nükleer edecek yardımcısı hakan cumhurbaşkanlığı güney kendi olduğunu ceza bugün terk\n",
            "Topic 19:\n",
            "ın suriye abd çıktı yok bakanı deki türkiye iddiası rusya ortaya dışişleri demirtaş olan silah genel nde ran bm artık\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}